{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "1_naive_bayes.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dkswndms4782/BoostCamp_AI_Tech/blob/main/1_naive_bayes.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BvEk93OpD-8Q"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zUp6U7Q6PmSW",
        "outputId": "7ffe6e03-628b-4758-94fa-8e81e568ef7f"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "btDmoiRCRfMp"
      },
      "source": [
        "## **1. NaiveBayes Classifier**\r\n",
        "1. 주어진 데이터를 전처리합니다.\r\n",
        "2. NaiveBayes 분류기 모델을 구현하고 학습 데이터로 이를 학습시킵니다.\r\n",
        "3. 간단한 test case로 결과를 확인합니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3a3E1pbkSYSF"
      },
      "source": [
        "### **필요 패키지 import**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6GKm6PwhiGxv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5eff5f4a-ecda-403d-f2ec-23e7ab0532df"
      },
      "source": [
        "!pip install konlpy"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting konlpy\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/85/0e/f385566fec837c0b83f216b2da65db9997b35dd675e107752005b7d392b1/konlpy-0.5.2-py2.py3-none-any.whl (19.4MB)\n",
            "\u001b[K     |████████████████████████████████| 19.4MB 66.7MB/s \n",
            "\u001b[?25hCollecting colorama\n",
            "  Downloading https://files.pythonhosted.org/packages/44/98/5b86278fbbf250d239ae0ecb724f8572af1c91f4a11edf4d36a206189440/colorama-0.4.4-py2.py3-none-any.whl\n",
            "Requirement already satisfied: lxml>=4.1.0 in /usr/local/lib/python3.6/dist-packages (from konlpy) (4.2.6)\n",
            "Collecting tweepy>=3.7.0\n",
            "  Downloading https://files.pythonhosted.org/packages/67/c3/6bed87f3b1e5ed2f34bd58bf7978e308c86e255193916be76e5a5ce5dfca/tweepy-3.10.0-py2.py3-none-any.whl\n",
            "Requirement already satisfied: numpy>=1.6 in /usr/local/lib/python3.6/dist-packages (from konlpy) (1.19.5)\n",
            "Collecting beautifulsoup4==4.6.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9e/d4/10f46e5cfac773e22707237bfcd51bbffeaf0a576b0a847ec7ab15bd7ace/beautifulsoup4-4.6.0-py3-none-any.whl (86kB)\n",
            "\u001b[K     |████████████████████████████████| 92kB 7.6MB/s \n",
            "\u001b[?25hCollecting JPype1>=0.7.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/de/af/93f92b38ec1ff3091cd38982ed19cea2800fefb609b5801c41fc43c0781e/JPype1-1.2.1-cp36-cp36m-manylinux2010_x86_64.whl (457kB)\n",
            "\u001b[K     |████████████████████████████████| 460kB 38.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tweepy>=3.7.0->konlpy) (1.3.0)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tweepy>=3.7.0->konlpy) (1.15.0)\n",
            "Requirement already satisfied: requests[socks]>=2.11.1 in /usr/local/lib/python3.6/dist-packages (from tweepy>=3.7.0->konlpy) (2.23.0)\n",
            "Requirement already satisfied: typing-extensions; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from JPype1>=0.7.0->konlpy) (3.7.4.3)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->tweepy>=3.7.0->konlpy) (3.1.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (2020.12.5)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6; extra == \"socks\" in /usr/local/lib/python3.6/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (1.7.1)\n",
            "Installing collected packages: colorama, tweepy, beautifulsoup4, JPype1, konlpy\n",
            "  Found existing installation: tweepy 3.6.0\n",
            "    Uninstalling tweepy-3.6.0:\n",
            "      Successfully uninstalled tweepy-3.6.0\n",
            "  Found existing installation: beautifulsoup4 4.6.3\n",
            "    Uninstalling beautifulsoup4-4.6.3:\n",
            "      Successfully uninstalled beautifulsoup4-4.6.3\n",
            "Successfully installed JPype1-1.2.1 beautifulsoup4-4.6.0 colorama-0.4.4 konlpy-0.5.2 tweepy-3.10.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2srhF-lp4JxL"
      },
      "source": [
        "from tqdm import tqdm\r\n",
        "\r\n",
        "# 다양한 한국어 형태소 분석기가 클래스로 구현되어 있음\r\n",
        "from konlpy import tag \r\n",
        "\r\n",
        "from collections import defaultdict\r\n",
        "\r\n",
        "import math"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rpgjbzqr6UR4"
      },
      "source": [
        "### **학습 및 테스트 데이터 전처리**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DTRXq_6G7wTk"
      },
      "source": [
        "Sample 데이터를 확인합니다.  \r\n",
        "긍정($1$), 부정($0$) 2가지 class로 구성되어 있습니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MCBnEQrfoL_C"
      },
      "source": [
        "train_data = [\r\n",
        "  \"정말 맛있습니다. 추천합니다.\",\r\n",
        "  \"기대했던 것보단 별로였네요.\",\r\n",
        "  \"다 좋은데 가격이 너무 비싸서 다시 가고 싶다는 생각이 안 드네요.\",\r\n",
        "  \"완전 최고입니다! 재방문 의사 있습니다.\",\r\n",
        "  \"음식도 서비스도 다 만족스러웠습니다.\",\r\n",
        "  \"위생 상태가 좀 별로였습니다. 좀 더 개선되기를 바랍니다.\",\r\n",
        "  \"맛도 좋았고 직원분들 서비스도 너무 친절했습니다.\",\r\n",
        "  \"기념일에 방문했는데 음식도 분위기도 서비스도 다 좋았습니다.\",\r\n",
        "  \"전반적으로 음식이 너무 짰습니다. 저는 별로였네요.\",\r\n",
        "  \"위생에 조금 더 신경 썼으면 좋겠습니다. 조금 불쾌했습니다.\"\r\n",
        "]\r\n",
        "train_labels = [1, 0, 0, 1, 1, 0, 1, 1, 0, 0]\r\n",
        "\r\n",
        "test_data = [\r\n",
        "  \"정말 좋았습니다. 또 가고 싶네요.\",\r\n",
        "  \"별로였습니다. 되도록 가지 마세요.\",\r\n",
        "  \"다른 분들께도 추천드릴 수 있을 만큼 만족했습니다.\",\r\n",
        "  \"서비스가 좀 더 개선되었으면 좋겠습니다. 기분이 좀 나빴습니다.\"\r\n",
        "]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dQ7rMLICacVN"
      },
      "source": [
        "KoNLPy 패키지에서 제공하는 Twitter(Okt) tokenizer를 사용하여 tokenization합니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bEzeYDmPjNLl"
      },
      "source": [
        "tokenizer = tag.Okt()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tftxirx_7sk7"
      },
      "source": [
        "def make_tokenized(data):\r\n",
        "  tokenized = []  # 단어 단위로 나뉜 리뷰 데이터.\r\n",
        "\r\n",
        "  for sent in tqdm(data):\r\n",
        "    tokens = tokenizer.morphs(sent)\r\n",
        "    tokenized.append(tokens)\r\n",
        "\r\n",
        "  return tokenized"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I4VEZyFlCqi-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "79b829c2-20e9-4521-b541-af1c468f3930"
      },
      "source": [
        "train_tokenized = make_tokenized(train_data)\r\n",
        "test_tokenized = make_tokenized(test_data)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 10/10 [00:06<00:00,  1.61it/s]\n",
            "100%|██████████| 4/4 [00:00<00:00, 42.13it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OEhn3uv2o2kt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4953c431-e307-41f4-e54c-e1c9f175d828"
      },
      "source": [
        "train_tokenized"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['정말', '맛있습니다', '.', '추천', '합니다', '.'],\n",
              " ['기대했던', '것', '보단', '별로', '였네요', '.'],\n",
              " ['다',\n",
              "  '좋은데',\n",
              "  '가격',\n",
              "  '이',\n",
              "  '너무',\n",
              "  '비싸서',\n",
              "  '다시',\n",
              "  '가고',\n",
              "  '싶다는',\n",
              "  '생각',\n",
              "  '이',\n",
              "  '안',\n",
              "  '드네',\n",
              "  '요',\n",
              "  '.'],\n",
              " ['완전', '최고', '입니다', '!', '재', '방문', '의사', '있습니다', '.'],\n",
              " ['음식', '도', '서비스', '도', '다', '만족스러웠습니다', '.'],\n",
              " ['위생',\n",
              "  '상태',\n",
              "  '가',\n",
              "  '좀',\n",
              "  '별로',\n",
              "  '였습니다',\n",
              "  '.',\n",
              "  '좀',\n",
              "  '더',\n",
              "  '개선',\n",
              "  '되',\n",
              "  '기를',\n",
              "  '바랍니다',\n",
              "  '.'],\n",
              " ['맛', '도', '좋았고', '직원', '분들', '서비스', '도', '너무', '친절했습니다', '.'],\n",
              " ['기념일',\n",
              "  '에',\n",
              "  '방문',\n",
              "  '했는데',\n",
              "  '음식',\n",
              "  '도',\n",
              "  '분위기',\n",
              "  '도',\n",
              "  '서비스',\n",
              "  '도',\n",
              "  '다',\n",
              "  '좋았습니다',\n",
              "  '.'],\n",
              " ['전반', '적', '으로', '음식', '이', '너무', '짰습니다', '.', '저', '는', '별로', '였네요', '.'],\n",
              " ['위생', '에', '조금', '더', '신경', '썼으면', '좋겠습니다', '.', '조금', '불쾌했습니다', '.']]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SVPd7lQjbfNO"
      },
      "source": [
        "학습데이터 기준으로 가장 많이 등장한 단어부터 순서대로 vocab에 추가합니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w1S1egKgeJzM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4c6907b0-7e15-4b22-fc4c-1e0062165ce3"
      },
      "source": [
        "word_count = defaultdict(int)  # Key: 단어, Value: 등장 횟수\r\n",
        "\r\n",
        "for tokens in tqdm(train_tokenized):\r\n",
        "  for token in tokens:\r\n",
        "    word_count[token] += 1"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 10/10 [00:00<00:00, 13551.87it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I0LPetURIdxK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f8147db8-c8c6-4bed-cdd8-6f3842ac0f01"
      },
      "source": [
        "word_count = sorted(word_count.items(), key=lambda x: x[1], reverse=True)\r\n",
        "print(len(word_count))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "66\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "vTokka9YjPTd",
        "outputId": "075faf2c-d3c6-4c00-d843-44ab46a3a31f"
      },
      "source": [
        "a = defaultdict(int)\r\n",
        "a['b'] +=1\r\n",
        "sorted(a.it)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-10-75b7ca923f5a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdefaultdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'b'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mit\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m: 'collections.defaultdict' object has no attribute 'it'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tI2p2T1CJMlB"
      },
      "source": [
        "w2i = {}  # Key: 단어, Value: 단어의 index\r\n",
        "for pair in tqdm(word_count):\r\n",
        "  if pair[0] not in w2i:\r\n",
        "    w2i[pair[0]] = len(w2i)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cG3kuKkNKj0Z"
      },
      "source": [
        "len(w2i)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XIy3zcUSXNuR"
      },
      "source": [
        "w2i"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "85oCOe0Xqcwk"
      },
      "source": [
        "### **모델 Class 구현**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w3uuFi52qjh6"
      },
      "source": [
        "NaiveBayes Classifier 모델 클래스를 구현합니다.\r\n",
        "\r\n",
        "*   `self.k`: Smoothing을 위한 상수.\r\n",
        "*   `self.w2i`: 사전에 구한 vocab.\r\n",
        "*   `self.priors`: 각 class의 prior 확률.\r\n",
        "*   `self.likelihoods`: 각 token의 특정 class 조건 내에서의 likelihood.\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TsZlgjkBHAod"
      },
      "source": [
        "class NaiveBayesClassifier():\r\n",
        "  def __init__(self, w2i, k=0.1):\r\n",
        "    self.k = k\r\n",
        "    self.w2i = w2i\r\n",
        "    self.priors = {}\r\n",
        "    self.likelihoods = {}\r\n",
        "\r\n",
        "  def train(self, train_tokenized, train_labels):\r\n",
        "    self.set_priors(train_labels)  # Priors 계산.\r\n",
        "    self.set_likelihoods(train_tokenized, train_labels)  # Likelihoods 계산.\r\n",
        "\r\n",
        "  def inference(self, tokens):\r\n",
        "    log_prob0 = 0.0\r\n",
        "    log_prob1 = 0.0\r\n",
        "\r\n",
        "    for token in tokens:\r\n",
        "      if token in self.likelihoods:  # 학습 당시 추가했던 단어에 대해서만 고려.\r\n",
        "        log_prob0 += math.log(self.likelihoods[token][0])\r\n",
        "        log_prob1 += math.log(self.likelihoods[token][1])\r\n",
        "\r\n",
        "    # 마지막에 prior를 고려.\r\n",
        "    log_prob0 += math.log(self.priors[0])\r\n",
        "    log_prob1 += math.log(self.priors[1])\r\n",
        "\r\n",
        "    if log_prob0 >= log_prob1:\r\n",
        "      return 0\r\n",
        "    else:\r\n",
        "      return 1\r\n",
        "\r\n",
        "  def set_priors(self, train_labels):\r\n",
        "    class_counts = defaultdict(int)\r\n",
        "    for label in tqdm(train_labels):\r\n",
        "      class_counts[label] += 1\r\n",
        "    \r\n",
        "    for label, count in class_counts.items():\r\n",
        "      self.priors[label] = class_counts[label] / len(train_labels)\r\n",
        "\r\n",
        "  def set_likelihoods(self, train_tokenized, train_labels):\r\n",
        "    token_dists = {}  # 각 단어의 특정 class 조건 하에서의 등장 횟수.\r\n",
        "    class_counts = defaultdict(int)  # 특정 class에서 등장한 모든 단어의 등장 횟수.\r\n",
        "\r\n",
        "    for i, label in enumerate(tqdm(train_labels)):\r\n",
        "      count = 0\r\n",
        "      for token in train_tokenized[i]:\r\n",
        "        if token in self.w2i:  # 학습 데이터로 구축한 vocab에 있는 token만 고려.\r\n",
        "          if token not in token_dists:\r\n",
        "            token_dists[token] = {0:0, 1:0}\r\n",
        "          token_dists[token][label] += 1\r\n",
        "          count += 1\r\n",
        "      class_counts[label] += count\r\n",
        "\r\n",
        "    for token, dist in tqdm(token_dists.items()):\r\n",
        "      if token not in self.likelihoods:\r\n",
        "        self.likelihoods[token] = {\r\n",
        "            0:(token_dists[token][0] + self.k) / (class_counts[0] + len(self.w2i)*self.k),\r\n",
        "            1:(token_dists[token][1] + self.k) / (class_counts[1] + len(self.w2i)*self.k),\r\n",
        "        }"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xzjVUyBOQEJk"
      },
      "source": [
        "### **모델 학습**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HuE3mFM46VBP"
      },
      "source": [
        "모델 객체를 만들고 학습 데이터로 학습시킵니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wt-iUEVRNsRj"
      },
      "source": [
        "classifier = NaiveBayesClassifier(w2i)\r\n",
        "classifier.train(train_tokenized, train_labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h79XWrsnQJtN"
      },
      "source": [
        "### **테스트**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pjk05W136d5o"
      },
      "source": [
        "Test sample에 대한 결과는 다음과 같습니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fe-fOScGNzH3"
      },
      "source": [
        "preds = []\r\n",
        "for test_tokens in tqdm(test_tokenized):\r\n",
        "  pred = classifier.inference(test_tokens)\r\n",
        "  preds.append(pred)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hrYMTKM10vYk"
      },
      "source": [
        "preds"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4b68-Bh5zArE"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}